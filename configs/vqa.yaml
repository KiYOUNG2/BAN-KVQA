DataArguments:

  # DataPathArguments
  dataset_path: ./data
  preprocessing_num_workers: 1
  
  # TokenizerArguments
  max_seq_length: 16
  pad_to_max_length: True

ModelArguments:

  # ModelArguments
  model_name_or_path: klue/roberta-base
  architectures: bertrnn
  config_name: null
  tokenizer_name: null
  model_cache_dir: cache
  model_cache_dir: None
  model_init: ban

  # ModelHeadArguments
  model_head: bertrnn

  # VQAArguments
  num_classes: 2423
  v_dim: 2048
  num_hid: 768
  op: null
  gamma: 8
  finetune_q: False 
  on_do_q: False

TrainingArguments:

  # HfTrainingArguments
  output_dir: ./saved_models/ban-kvqa-roberta-base-rnn
  # overwrite_output_dir: False
  learning_rate: 1e-3
  per_device_train_batch_size: 64
  per_device_eval_batch_size: 128
  num_train_epochs: 20

ProjectArguments:
  
  # AnalyzerArguments
  wandb_project: vqq
  checkpoint: null